name: Historical Data Fetch (5 Years)

on:
  workflow_dispatch:
    inputs:
      start_year:
        description: 'Start year for historical data (default: 5 years ago)'
        required: false
        type: string
        default: ''
      end_year:
        description: 'End year for historical data (default: current year)'
        required: false
        type: string
        default: ''
      geos:
        description: 'Comma-separated list of geo codes (default: US,GB,CA,AU)'
        required: false
        type: string
        default: 'US,GB,CA,AU'
      max_keywords:
        description: 'Maximum keywords to process (default: 100)'
        required: false
        type: string
        default: '100'
      time_budget_hours:
        description: 'Time budget in hours (default: 6)'
        required: false
        type: string
        default: '6'

permissions:
  contents: read

concurrency:
  group: historical-fetch
  cancel-in-progress: false

jobs:
  historical-fetch:
    runs-on: ubuntu-latest
    timeout-minutes: 420  # 7 hours to allow for long-running historical fetch

    env:
      # Required
      DATABASE_URL: ${{ secrets.DATABASE_URL }}

      # Configuration
      ENVIRONMENT: production
      TRENDS_GEOS: ${{ inputs.geos }}
      MAX_KEYWORDS: ${{ inputs.max_keywords }}
      TIME_BUDGET_HOURS: ${{ inputs.time_budget_hours }}
      START_YEAR: ${{ inputs.start_year }}
      END_YEAR: ${{ inputs.end_year }}

      # Python improves logging flush
      PYTHONUNBUFFERED: "1"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: |
            requirements.txt

      - name: Install dependencies
        run: |
          python -V
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run historical data fetch
        run: |
          set -e
          echo "Starting historical data fetch..."
          echo "Configuration:"
          echo "- TRENDS_GEOS: ${TRENDS_GEOS:-US,GB,CA,AU}"
          echo "- MAX_KEYWORDS: ${MAX_KEYWORDS:-100}"
          echo "- TIME_BUDGET_HOURS: ${TIME_BUDGET_HOURS:-6}"
          echo "- START_YEAR: ${START_YEAR:-auto}"
          echo "- END_YEAR: ${END_YEAR:-auto}"
          
          # Convert time budget to seconds for the script
          TIME_BUDGET_SECONDS=$((${TIME_BUDGET_HOURS:-6} * 3600))
          export TIME_BUDGET_SECONDS
          
          # Run the historical fetcher with retry logic
          ATTEMPTS=2
          for i in $(seq 1 $ATTEMPTS); do
            echo "Attempt $i of $ATTEMPTS"
            if python five_years_fetcher.py; then
              echo "Historical fetch completed successfully"
              exit 0
            fi
            echo "Attempt $i failed; sleeping before retry..."
            sleep 60
          done
          echo "All attempts failed"
          exit 1

      - name: Archive logs and results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: historical-fetch-logs
          path: |
            artifacts/
          retention-days: 30

      - name: Capture environment info
        if: always()
        run: |
          mkdir -p artifacts
          pip freeze > artifacts/pip-freeze.txt
          echo "Workflow completed at: $(date)" > artifacts/workflow-info.txt
          echo "Total runtime: $SECONDS seconds" >> artifacts/workflow-info.txt
          env | grep -E '^(ENVIRONMENT|TRENDS_GEOS|MAX_KEYWORDS|TIME_BUDGET|START_YEAR|END_YEAR)=' >> artifacts/workflow-info.txt || true
        shell: bash